{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Mini-projeto Naive Bayes e filtro de SPAM.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUf2_cONeIfp"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYTs9ZxXkmKp"
      },
      "source": [
        "# Importando o dataset e reprocessando as labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "yU7TfLX_foPm",
        "outputId": "573ba15b-e52f-44be-9629-557bbbae4bfc"
      },
      "source": [
        "df = pd.read_table('/content/SMSSpamCollection', names=['label', 'sms_message'])\n",
        "df.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ham</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ham</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>spam</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ham</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ham</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  label                                        sms_message\n",
              "0   ham  Go until jurong point, crazy.. Available only ...\n",
              "1   ham                      Ok lar... Joking wif u oni...\n",
              "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3   ham  U dun say so early hor... U c already then say...\n",
              "4   ham  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R6Z-oU8Dkrzz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "f07892c5-2912-4c44-8b72-9cec35744e05"
      },
      "source": [
        "df['label'] = df.label.map({'ham' : 0, 'spam' : 1})\n",
        "df.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>sms_message</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Ok lar... Joking wif u oni...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>U dun say so early hor... U c already then say...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label                                        sms_message\n",
              "0      0  Go until jurong point, crazy.. Available only ...\n",
              "1      0                      Ok lar... Joking wif u oni...\n",
              "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
              "3      0  U dun say so early hor... U c already then say...\n",
              "4      0  Nah I don't think he goes to usf, he lives aro..."
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tsieRPuu_nE3"
      },
      "source": [
        "# Bag of Words\n",
        "\n",
        "O Bag of Words é uma forma de representar problemas envolvendo diversas frase, em que vemos cada frase ignorando sua sintaxe e gramática, e apenas como um multiconjunto de palavras, ou seja, apenas vemos quais palavras e quantas de cada palavra estão na frase, como se a pegassemos e a jogassemos num saco de qualquer forma.\n",
        "\n",
        "Utiliza-se do Bag of Words pois algorítmos normalmente lidam melhor com números que com palavras, e esta é uma forma de se tomar dados numéricos das frases.\n",
        "\n",
        "Farei a implementação do Bag of Words do zero numa lista exemplo como é pedido no material."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d8TbkUe8Fxgq"
      },
      "source": [
        "Primeiramente passamos todos os strings da lista para letra minúscula."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn1ZUyQ_CL8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f293921a-df41-451d-d863-f3a54e8eff67"
      },
      "source": [
        "documents = ['Hello, how are you!',\n",
        "             'Win money, win from home.',\n",
        "             'Call me now.',\n",
        "             'Hello, Call hello you tomorrow?']\n",
        "\n",
        "lower_case_documents = []\n",
        "for i in documents:\n",
        "  i = i.lower()\n",
        "  lower_case_documents.append(i)\n",
        "print(lower_case_documents)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello, how are you!', 'win money, win from home.', 'call me now.', 'hello, call hello you tomorrow?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QaeUKUtgG0f-"
      },
      "source": [
        "Aí removemos a pontuação..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NooO_WgGG2S7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de6ae50a-a960-4c17-8af8-a767fc5eadb2"
      },
      "source": [
        "sans_punctuation_documents = []\n",
        "import string\n",
        "\n",
        "for i in lower_case_documents:\n",
        "  i = i.translate(str.maketrans('', '', string.punctuation))\n",
        "  sans_punctuation_documents.append(i)\n",
        "    \n",
        "print(sans_punctuation_documents)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello how are you', 'win money win from home', 'call me now', 'hello call hello you tomorrow']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sPYP9d1IAiu"
      },
      "source": [
        "Assim, tokenizamos os strings obtidos por os separar em cada palavra."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZKmgP7c5IUFm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de0aba6d-0314-4450-bdfd-9c5b341c7348"
      },
      "source": [
        "preprocessed_documents = []\n",
        "for i in sans_punctuation_documents:\n",
        "  preprocessed_documents.append(i.split(' '))\n",
        "print(preprocessed_documents)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['hello', 'how', 'are', 'you'], ['win', 'money', 'win', 'from', 'home'], ['call', 'me', 'now'], ['hello', 'call', 'hello', 'you', 'tomorrow']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQgNs27EKF8S"
      },
      "source": [
        "E contamos as frequências."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IMcqmwwsKJE5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e970122-86be-4859-b0d0-d898ead9553e"
      },
      "source": [
        "frequency_list = []\n",
        "import pprint\n",
        "from collections import Counter\n",
        "\n",
        "for i in preprocessed_documents:\n",
        "  frequency_list.append(Counter(i))\n",
        "    \n",
        "pprint.pprint(frequency_list)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Counter({'hello': 1, 'how': 1, 'are': 1, 'you': 1}),\n",
            " Counter({'win': 2, 'money': 1, 'from': 1, 'home': 1}),\n",
            " Counter({'call': 1, 'me': 1, 'now': 1}),\n",
            " Counter({'hello': 2, 'call': 1, 'you': 1, 'tomorrow': 1})]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yo776NGuM7gV"
      },
      "source": [
        "Feita esta implementação pedida, implementamos o Bag of Words pelo scikit-learn.\n",
        "\n",
        "Primeiro importamos o CountVectorizer para vermos as palavras encontradas em \"documents\"."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WibRVLg_NMSX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3340382f-f2cd-4fde-88af-dac50bfef4e4"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vector = CountVectorizer()\n",
        "\n",
        "count_vector.fit(documents)\n",
        "count_vector.get_feature_names()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['are',\n",
              " 'call',\n",
              " 'from',\n",
              " 'hello',\n",
              " 'home',\n",
              " 'how',\n",
              " 'me',\n",
              " 'money',\n",
              " 'now',\n",
              " 'tomorrow',\n",
              " 'win',\n",
              " 'you']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHSHnxHBRZad"
      },
      "source": [
        "Agora as organizamos em uma matriz mostrando a contagem das palavras em cada frase, em que cada linha é uma frase e cada coluna uma palavra."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R_uaAEp1QB4l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c262e802-f73f-4c41-8312-ab5787e8c779"
      },
      "source": [
        "doc_array = count_vector.transform(documents).toarray()\n",
        "doc_array"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1],\n",
              "       [0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 2, 0],\n",
              "       [0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0],\n",
              "       [0, 1, 0, 2, 0, 0, 0, 0, 0, 1, 0, 1]])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1izAJFEkRhzf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "cbf641b6-dd75-4da5-c628-78395619cd43"
      },
      "source": [
        "frequency_matrix = pd.DataFrame(doc_array,columns = count_vector.get_feature_names())\n",
        "frequency_matrix"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>are</th>\n",
              "      <th>call</th>\n",
              "      <th>from</th>\n",
              "      <th>hello</th>\n",
              "      <th>home</th>\n",
              "      <th>how</th>\n",
              "      <th>me</th>\n",
              "      <th>money</th>\n",
              "      <th>now</th>\n",
              "      <th>tomorrow</th>\n",
              "      <th>win</th>\n",
              "      <th>you</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   are  call  from  hello  home  how  me  money  now  tomorrow  win  you\n",
              "0    1     0     0      1     0    1   0      0    0         0    0    1\n",
              "1    0     0     1      0     1    0   0      1    0         0    2    0\n",
              "2    0     1     0      0     0    0   1      0    1         0    0    0\n",
              "3    0     1     0      2     0    0   0      0    0         1    0    1"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4TcRfl4C5egs"
      },
      "source": [
        "# Conjuntos de treinamento e teste\n",
        "\n",
        "Separarei os dados em conjuntos de teste e de treinamento para aplicar no modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_kDDDIiS6HAy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4353b202-4020-491b-85dc-b76e5602f5df"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['sms_message'], \n",
        "                                                    df['label'], \n",
        "                                                    random_state=1)\n",
        "\n",
        "print('Number of rows in the total set: {}'.format(df.shape[0]))\n",
        "print('Number of rows in the training set: {}'.format(X_train.shape[0]))\n",
        "print('Number of rows in the test set: {}'.format(X_test.shape[0]))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of rows in the total set: 5572\n",
            "Number of rows in the training set: 4179\n",
            "Number of rows in the test set: 1393\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xCMMOdyd-Nly"
      },
      "source": [
        "E aplicamos o bag of words nestes dados."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CjK3y3yg-NRv"
      },
      "source": [
        "count_vector = CountVectorizer()\n",
        "training_data = count_vector.fit_transform(X_train)\n",
        "testing_data = count_vector.transform(X_test)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibdmyS2CAj8Q"
      },
      "source": [
        "# Implementando o teorema de Bayes do zero e especificidade e sensitividade\n",
        "\n",
        "Dado um problema de decidir se um dado possui um valor positivo ou um valor negativo, e um teste que decide se o valor de algum dado dado é positivo ou negativo, a sensibilidade do teste é a probabilidade de que o teste nos retorne que o dado possui valor positivo caso o dado realmente possua valor positivo, e a especifidade do teste é a probabilidade de que o teste nos retorne um valor negativo no caso em que o valor do dado realmente seja negativo.\n",
        "\n",
        "Estes são valores normalmente diferentes, pois, por exemplo, um teste que dá valor positivo para todos os dados recebidos terá uma sensibilidade de 100%, mas errará todos os valores negativos, dando uma especifidade de 0%. Idealmente quereriamos uma especifidade e uma sensibilidade ambos de 100%, mas nem sempre isto é possível, e muitas vezes procurar aumentar a sensibilidade diminui a especifidade e vice-versa. Assim, é bom procurar um balanço de ambos, ou decidir qual é mais importante de se valorizar.\n",
        "\n",
        "Um exemplo em que a sensibilidade é mais adequada seria o de alguma doença letal, em que uma pessoa ou possui a doença ou não a possui, e é feito um teste para se descobrir isto, neste caso para evitar mortes com um tratamento adequado de quem realmente possui a doença, é mais importante que as chances de que o teste dê positivo para quem possui a doença sejam maiores.\n",
        "\n",
        "Agora, se a doença não for letal ou decapacitante, como um pequeno resfriado, pode ser interessante para os médicos darem prioridade à especifidade, pois caso muitos pacientes apresentarem resultados positivos para uma doença que eles não possuem, os médicos poderão gastar muitos recursos e tempo com o tratamento destes pacientes de forma desnecessária.\n",
        "\n",
        "Agora vamos à implementação pedida no material, no exemplo da diabetes, completandos os tópicos em ToDo desta seção."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "93XHEO34Ph9c",
        "outputId": "d2f258ea-b39f-4abe-8f1d-6f0448b53bfb"
      },
      "source": [
        "# P(D)\n",
        "p_diabetes = 0.01\n",
        "\n",
        "# P(~D)\n",
        "p_no_diabetes = 0.99\n",
        "\n",
        "# Sensitivity or P(Pos|D)\n",
        "p_pos_diabetes = 0.9\n",
        "\n",
        "# Specificity or P(Neg/~D)\n",
        "p_neg_no_diabetes = 0.9\n",
        "\n",
        "# P(Pos)\n",
        "p_pos = p_diabetes * p_pos_diabetes + p_no_diabetes * (1-p_neg_no_diabetes)\n",
        "print('The probability of getting a positive test result P(Pos) is:',format(p_pos))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of getting a positive test result P(Pos) is: 0.10799999999999998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hn957fEMQ5rh",
        "outputId": "820e3f35-62dc-4e20-cf0a-e7a9151bc59d"
      },
      "source": [
        "p_diabetes_pos = (p_diabetes * p_pos_diabetes)/p_pos\n",
        "print('Probability of an individual having diabetes, given that that individual got a positive test result is:\\\n",
        "',format(p_diabetes_pos)) "
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of an individual having diabetes, given that that individual got a positive test result is: 0.08333333333333336\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuF3AQ-1RVvc",
        "outputId": "1c6c4093-755b-4cf7-9df9-be0874a15e7a"
      },
      "source": [
        "# P(Pos/~D)\n",
        "p_pos_no_diabetes = 0.1\n",
        "\n",
        "# P(~D|Pos)\n",
        "p_no_diabetes_pos = (p_no_diabetes * p_pos_no_diabetes)/p_pos\n",
        "print('Probability of an individual not having diabetes, given that that individual got a positive test result is: {}',format(p_no_diabetes_pos))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of an individual not having diabetes, given that that individual got a positive test result is: {} 0.9166666666666669\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementando o Naive Bayes do zero\n",
        "\n",
        "Bem, aqui seguirei os passos pedidos pelo material para fazer os cálculos de probabilidade envolvendo as falas dos candidatos dos partidos políticos."
      ],
      "metadata": {
        "id": "SIsQa3__omDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# P(J)\n",
        "p_j = 0.5\n",
        "\n",
        "# P(F/J)\n",
        "p_j_f = 0.1\n",
        "\n",
        "# P(I/J)\n",
        "p_j_i = 0.1\n",
        "\n",
        "p_j_text = p_j*p_j_f*p_j_i\n",
        "print(p_j_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWoymM5ZqX7_",
        "outputId": "4a76561d-32eb-4776-bd60-47a9137914fa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.005000000000000001\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# P(G)\n",
        "p_g = 0.5\n",
        "\n",
        "# P(F/G)\n",
        "p_g_f = 0.7\n",
        "\n",
        "# P(I/G)\n",
        "p_g_i = 0.2\n",
        "\n",
        "p_g_text = p_g*p_g_f*p_g_i\n",
        "print(p_g_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "56k8h9PPqoWH",
        "outputId": "34a7ac27-468f-457e-da83-7a0b78177203"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.06999999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_f_i = p_j_text + p_g_text\n",
        "print('Probability of words freedom and immigration being said are: ', format(p_f_i))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fLOj9UlRqynV",
        "outputId": "042cbcd2-25f7-4603-d182-0c69114ca7df"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of words freedom and immigration being said are:  0.075\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_j_fi = p_j_text/p_f_i\n",
        "print('The probability of Jill Stein saying the words Freedom and Immigration: ', format(p_j_fi))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogFkyUQArv2J",
        "outputId": "1896f17f-43ec-4f92-91ca-5a3e3f9899e4"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of Jill Stein saying the words Freedom and Immigration:  0.06666666666666668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "p_g_fi = p_g_text/p_f_i\n",
        "print('The probability of Gary Johnson saying the words Freedom and Immigration: ', format(p_g_fi))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiB_iucZsrNj",
        "outputId": "a7ad5be3-ae6c-47d3-af34-36ef30de0a42"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The probability of Gary Johnson saying the words Freedom and Immigration:  0.9333333333333332\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implementação do Naive Bayes com o scikit-learn\n",
        "\n",
        "Agora utilizamos o pacote scikit-learn para utilizar o Naive Bayes para treinar com nossa data de treinamento e fazer previsões sobre a data de teste."
      ],
      "metadata": {
        "id": "ypptcuy_t2Fv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "naive_bayes = MultinomialNB()\n",
        "naive_bayes.fit(training_data,y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ccyz7k5RIWeE",
        "outputId": "6515fa03-3192-491c-9248-82ed35ded27c"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = naive_bayes.predict(testing_data)"
      ],
      "metadata": {
        "id": "i0o9Um-0I6eJ"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Avaliando o modelo\n",
        "\n",
        "Por fim, vemos se o modelo previu bem os dados que deixamos para teste."
      ],
      "metadata": {
        "id": "MvOEUNpuLvq2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "print('Accuracy score: ', format(accuracy_score(y_test, predictions)))\n",
        "print('Precision score: ', format(precision_score(y_test, predictions)))\n",
        "print('Recall score: ', format(recall_score(y_test, predictions)))\n",
        "print('F1 score: ', format(f1_score(y_test, predictions)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8MSL-I31xKw7",
        "outputId": "5c34720e-f1be-4db1-925e-7be2351aa8f9"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score:  0.9885139985642498\n",
            "Precision score:  0.9720670391061452\n",
            "Recall score:  0.9405405405405406\n",
            "F1 score:  0.9560439560439562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Comparando algoritmos\n",
        "\n",
        "Treinaremos agora com o algoritmo Decision Tree o mesmo conjunto de treino para compararmos o modelo recebido com o modelo feito pelo Naive Bayes.\n"
      ],
      "metadata": {
        "id": "IxAeCtCTy6EH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "tree = DecisionTreeClassifier(max_depth = 10)\n",
        "tree.fit(training_data, y_train)\n",
        "\n",
        "predictionstree = tree.predict(testing_data)\n",
        "\n",
        "print('Accuracy score: ', format(accuracy_score(y_test, predictionstree)))\n",
        "print('Precision score: ', format(precision_score(y_test, predictionstree)))\n",
        "print('Recall score: ', format(recall_score(y_test, predictionstree)))\n",
        "print('F1 score: ', format(f1_score(y_test, predictionstree)))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pNqB0VbM3bYQ",
        "outputId": "96231154-e5ba-476d-e462-95d2b115d84c"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy score:  0.9597989949748744\n",
            "Precision score:  0.8603351955307262\n",
            "Recall score:  0.8324324324324325\n",
            "F1 score:  0.8461538461538461\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vemos que o Decision Tree, mesmo se mostrando um pouco decente, é pior que o Naive Bayes em todos os scores, de modo que o melhor modelo é o obtido pelo Naive Bayes. Especialmente, o precision score do Decision Tree é um tanto menor, indicando que estamos detectando como SPAM mais emails legítimos que podem ser importantes para o usuário que o modelo do Naive Bayes, o que é bastante indesejável.\n",
        "\n",
        "Listarei os prós e contras de ambos os algoritmos."
      ],
      "metadata": {
        "id": "CSWSPJXR8Ct1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes:\n",
        "\n",
        "Contras:\n",
        "- Devemos assumir independência dos dados.\n",
        "\n",
        "- Caso uma categoria não esteja no conjunto de treinamento, o Naive Bayes derá uma frequência nula para esta categoria, ou seja, não conseguirá prever bem datas com categorias novas.\n",
        "\n",
        "- Fazemos várias suposições sobre a distribuição do modelo que não são necessariamente verdadeiras.\n",
        "\n",
        "\n",
        "Prós:\n",
        "\n",
        "- É bom quando os datasets são pequenos e as features são independentes.\n",
        "\n",
        "- E fácil de implementar.\n",
        "\n",
        "- Pode ser paramétrico ou não paramétrico.\n",
        "\n",
        "- Eficiente para classificação de documentos e filtro de SPAM."
      ],
      "metadata": {
        "id": "kDxbzQAZkq4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decision Tree\n",
        "\n",
        "Contras:\n",
        "\n",
        "- É sensível à rotação dos dados.\n",
        "\n",
        "- Se não fixarmos uma semente, o mesmo dataset pode ser treinado em árvores diferentes, dando uma aleatoriedade maior para o algoritmo.\n",
        "\n",
        "- Tende a se sobreajustar ao conjunto de treinamento.\n",
        "\n",
        "Prós:\n",
        "\n",
        "- É fácil de se interpretar e se explicar para outros, tendo também uma forma bem interessante de se visualizar.\n",
        "\n",
        "- Pode ser usado tanto para regressão quanto para classificação de dados.\n",
        "\n",
        "- Não precisa centralizar ou escalar os atributos.\n",
        "\n",
        "- Pode lidar com features não lineares."
      ],
      "metadata": {
        "id": "9jkyChA8kkq4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por mais que a Decision Tree também possa ser usada para classificação de dados, o Naive Bayes o sobressaiu provavelmente pois o conjunto de dados não é muito grande, situação que é uma especialidade maior do Naive Bayes que da Decision Tree."
      ],
      "metadata": {
        "id": "41UcK_i2sQrU"
      }
    }
  ]
}